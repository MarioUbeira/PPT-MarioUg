# Pedra, Papel, Tesoiras - Mario Ubeira GonzÃ¡lez

Repositorio para o proxecto Pedra, Papel, Tesoiras da materia Modelos de Intelixencia Artificial.  

O obxectivo principal desta tarefa Ã© crear un axente que trate de obter a mellor porcentaxe de vitorias posibles no Pedra, Papel, Tesoiras. Para iso, optei por implementar un axente reactivo baseado en modelos, que se serve dun historial personalizado das xogadas de cada adversario para detectar patrÃ³ns no seu comportamento. Ademais disto, o axente emprega conceptos de probabilidade e as regras da cadea de Markov para predicir os movementos futuros do opoÃ±ente, optimizando asÃ­ as sÃºas decisiÃ³ns e maximizando as probabilidades de vitoria en cada partida.

## 1. EspecificaciÃ³n da contorna de tarefas  

| **Contorna de tarefas** | **Observable** | **Axentes** | **Determinista** | **EpisÃ³dico** | **EstÃ¡tico** | **Discreto** | **CoÃ±ecido** |  
|:-----------------------:|:--------------:|:-----------:|:----------------:|:-------------:|:------------:|:------------:|:------------:|  
| RPS                    | Parcial        | Multiaxente | EstocÃ¡stico      | EpisÃ³dico      | EstÃ¡tico      | Discreto      | CoÃ±ecido     |  

**RPS** â®ž Contorno simple, baseado na interacciÃ³n por turnos entre o modelo e o oponente.

**Parcial** â®ž O axente non ten acceso Ã¡ seguinte acciÃ³n do oponente nin Ã¡ lÃ³xica que rexe as sÃºas acciÃ³ns, pero si pode observar o historial de turnos xogados ata o momento.

**Multiaxente** â®ž InterveÃ±en na tarefa tanto o modelo como o seu oponente.

**EstocÃ¡stico** â®ž O resultado dunha acciÃ³n non Ã© completamente predecible, xa que depende tanto das decisiÃ³ns do oponente como de posibles compoÃ±entes de aleatoriedade no contorno.

**EpisÃ³dico** â®ž Cada partida Ã© independente do resto; o resultado dunha partida non afecta Ã¡ seguinte, aÃ­nda que o modelo pode valerse dos resultados anteriores para trazar a sÃºa estratexia.

**EstÃ¡tico** â®ž O escenario da tarefa non se modifica durante a partida, esta desenvÃ³lvese sen cambios dinÃ¡micos no entorno.

**Discreto** â®ž A variedade de acciÃ³ns/estados e finita (Pedra, Papel ou Tesoiras).

**CoÃ±ecido** â®ž As regras do xogo son coÃ±ecidas polos participantes e non se modifican en ningÃºn momento da partida.

## 2. IdentificaciÃ³n do tipo de axente e estrutura 

**Axente reactivo baseado en modelos**: Un axente reactivo baseado en modelos Ã© un xogador que, en lugar de simplemente reaccionar en base a instrucciÃ³ns preestablecidas, e capaz de lembrar o que sucedeu en partidas anteriores e utilizar esa informaciÃ³n para mellorar as sÃºas decisiÃ³ns futuras. Este tipo de axente non precisa facer cÃ¡lculos moi complexos nin planificar a longo prazo; o que lle permite responder de maneira inmediata aos movementos do adversario, pero facendo uso da experiencia. A sÃºa principal vantaxe Ã© que, ao almacenar e analizar os movementos anteriores, pode detectar patrÃ³ns no xogo do opoÃ±ente e adaptarse a eles, aumentando as sÃºas posibilidades de gaÃ±ar nas seguintes partidas.

En resumo, este axente aprende dos erros e acertos previos e utiliza esa memoria para tomar decisiÃ³ns mÃ¡is intelixentes e efectivas no xogo. Por iso, considÃ©roo o tipo de axente mÃ¡is adecuado para este caso.

![](./img/estrutura_do_axente.png)

ðŸ”´ **Axente** â®ž Ã‰ o xogador automatizado que toma decisiÃ³ns baseÃ¡ndose na informaciÃ³n acumulada das partidas anteriores e nos patrÃ³ns detectados no comportamento do opoÃ±ente. O axente actÃºa de maneira racional, buscando maximizar as sÃºas posibilidades de Ã©xito en cada partida.

ðŸŸ¢ **Sensores** â®ž Captan informaciÃ³n do entorno, como o Ãºltimo movemento do opoÃ±ente e o resultado da Ãºltima partida, actualizando asÃ­ os datos dispoÃ±ibles para o axente.

ðŸŸ  **Como Ã© o mundo agora** â®ž Xera unha representaciÃ³n actualizada do xogo, combinando a informaciÃ³n do Ãºltimo movemento do opoÃ±ente, os resultados recentes e os patrÃ³ns detectados no historial.

ðŸŸ£ **Estado** â®ž Almacena o historial das partidas anteriores, gardando os movementos do opoÃ±ente e os resultados das partidas. Esta informaciÃ³n permite identificar posibles patrÃ³ns de xogo do adversario.

ðŸŸ£ **Como evoluciona o mundo** â®ž Analiza as tendencias nos movementos do opoÃ±ente ao longo das partidas, baseÃ¡ndose nos datos almacenados no estado, para detectar cambios na estratexia do adversario.

ðŸŸ£ **Que efectos causan as miÃ±as acciÃ³ns**  â®ž AvalÃ­a os resultados das acciÃ³ns do axente (como a elecciÃ³n de pedra, papel ou tesoira) en funciÃ³n das reacciÃ³ns do opoÃ±ente, determinando se as estratexias empregadas foron efectivas ou non.

ðŸŸ  **Que acciÃ³n debo tomar** â®ž Decide cal Ã© a mellor opciÃ³n a xogar (pedra, papel ou tesoira) en funciÃ³n dos patrÃ³ns detectados, o estado actual do xogo e as regras definidas.

ðŸŸ£ **Regras de condiciÃ³nâ€“acciÃ³n** â®ž Conxunto de regras que guÃ­an as decisiÃ³ns do axente. Por exemplo, se detecta que o opoÃ±ente tende a repetir os seus Ãºltimos movementos, pode contrarrestalos baseÃ¡ndose no patrÃ³n identificado.

ðŸŸ¢ **Actuadores** â®ž Executan a decisiÃ³n tomada polo axente, seleccionando pedra, papel ou tesoira para xogar a seguinte partida.

ðŸ”´ **Medio ambiente** â®ž InclÃºe o opoÃ±ente e as regras do xogo, proporcionando ao axente o contexto no que se desenvolven as partidas.

## 3. AmpliaciÃ³n: RPSLS

VersiÃ³n ampliada RPSLS (Pedra, Papel, Tesoiras, Lagarto, Spock) implementada no xogo. Neste modo introdÃºcense dÃºas novas acciÃ³ns: Lagarto e Spock, coas seguintes regras adicionais:

**Pedra** â®ž GaÃ±a contra Tesoiras e Lagarto pero perde contra Papel e Spock.

**Papel** â®ž GaÃ±a contra Pedra e Spock pero perde contra Tesoiras e Lagarto.

**Tesoiras** â®ž GaÃ±a contra Papel e Lagarto pero perde contra Pedra e Spock.

**Lagarto** â®ž GaÃ±a contra Spock e Papel pero perde contra Tesoiras e Pedra.

**Spock** â®ž GaÃ±a contra Tesoiras e Pedra pero perde contra Papel e Lagarto.

Para xogar no modo RPSLS, debes seleccionalo ao comezo do programa mediante a terminal, cando apareza a seguinte mensaxe:
``` bash
Escolle o modo de xogo: RPS[0], RPSLS[1], Axuda[8], SaÃ­r[9]: 1
```

## 4. ConclusiÃ³ns

### 4.1 RPS

No modo RPS, tras probar distintas estratexias, deime conta de que Ã© un xogo moi simple e fÃ¡cil de predicir. Ao poder visualizar o historial de partidas na terminal, o usuario serÃ­a sempre capaz de determinar a lÃ³xica de movementos que segue o axente e adaptarse a ela. Isto evidÃ©nciase na imaxe, onde o meu irmÃ¡n, tras comezar perdendo contra o axente, foi capaz de intuÃ­r os seus movementos e vencelo despois de tan sÃ³ catro roldas:

![](./img/Rendemento_con_historial.png)

Con esta observaciÃ³n dÃ­nme conta de que, co historial visible, a mellor opciÃ³n para o axente serÃ­a actuar de maneira aleatoria ou utilizando patrÃ³ns mÃ­nimos indetectables, polo que decidÃ­n que o mellor serÃ­a borrar a terminal despois de cada partida.

Sen o historial de partidas, optei por un mÃ©todo que combina tres estratexias diferentes cun compoÃ±ente de aleatoriedade entre elas: 
- Un 45% das veces o axente intenta predir o seguinte movemento baseÃ¡ndose nunha matriz de Markov simple.
- Outro 45% actÃºa segundo a porcentaxe de uso de cada movemento do usuario.
- O 10% restante elixe un movemento de forma completamente aleatoria.

Ademais, engadÃ­n un comprobante para que, se se detecta algÃºn patrÃ³n simple no Ãºltimos tres movementos do usuario, o axente actÃºe en consecuencia. Isto implementouse co fin de que o axente fose o mÃ¡is impredicible posible.

En conclusiÃ³n, para que o meu axente lograse boas porcentaxes de vitoria sen ser facilmente explotable, tiven que achegar o seu razoamento Ã¡ aleatoriedade. Dado que sendo tan sinxelo o xogo, resulta moi fÃ¡cil detectar patrÃ³ns. AsÃ­ como o axente estÃ¡ programado para detectar e explotar patrÃ³ns, o usuario tamÃ©n pode contraatacar explotando os do axente. Por tanto, considero que o mÃ¡is efectivo Ã© dotar ao axente dunha pseudoaleatoriedade que lle permita predicir os movementos do usuario sen ser vulnerable a ser explotado.

### 4.1 RPSLS

O modo RPSLS engade mÃ¡is variantes ao xogo, o que o fai moito mÃ¡is difÃ­cil de predicir en comparaciÃ³n co modo RPS estÃ¡ndar. A inclusiÃ³n de dous movementos adicionais, Lagarto e Spock, incrementa a complexidade do xogo e reduce a posibilidade de detectar patrÃ³ns simples nas decisiÃ³ns do opoÃ±ente.

Este aumento da complexidade fai que teÃ±a mÃ¡is sentido dotar ao axente dunha intelixencia mÃ¡is avanzada. Neste modo, o uso de estratexias como a prediciÃ³n baseada en matrices de Markov e a anÃ¡lise probabilÃ­stico dos movementos do adversario vÃ³lvese mÃ¡is relevante. A maior variedade de combinaciÃ³ns posibles permite que o axente poida adaptarse mellor e optimizar as sÃºas decisiÃ³ns, maximizando asÃ­ as sÃºas probabilidades de vitoria.

En resumo, no RPSLS si que lle outorgo un maior valor a que o axente posÃºa unha intelixencia capaz de non sÃ³ reaccionar a patrÃ³ns mÃ¡is complexos, senÃ³n tamÃ©n de anticiparse a movementos menos obvios, facendo que sexa mÃ¡is impredicible e efectivo neste modo mÃ¡is amplio.

## 5. InstalaciÃ³n e uso

**1.** Creamos un cartafol para o repositorio e ubicÃ¡monos nel:
``` bash
mkdir cartafol_ppt
cd /ruta/ao/cartafol_ppt
```
**2.** Copiamos o enlace do repo e o clonamos no noso cartafol:
``` bash
git clone https://github.com/MarioUbeira/PPT-MarioUg.git
```
**3.** Creamos unha contorna virtual e a activamos:
> Linux e MacOS
``` bash
python3 -m venv nome_contorna
source nome_contorna/bin/activate
# Se aparece o nome da contorna no inicio do prompt significa que se activou correctamente:
# (nome_contorna) C:/ruta/ao/cartafol_ppt$
```
> Windows
``` powershell
python3 -m venv nome_contorna
.\nome_contorna\Scripts\activate
```
*NOTA: A activaciÃ³n da contorna virtual pode fallar en Windows se as polÃ­ticas de execuciÃ³n estÃ¡n restrinxidas, nese caso utilizar o seguinte comando:*
``` powershell
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```
**4.** Descargamos e instalamos as dependencias:
``` bash
pip install -r requirements.txt
```
**5.** ExecuciÃ³n do programa:
> Linux e MacOS
``` bash
python3 src/main.py
```
> Windows
``` powershell
python3 .\src\main.py
```