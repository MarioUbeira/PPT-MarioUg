# Pedra, Papel, Tesoiras - Mario Ubeira Gonz√°lez

Repositorio para o proxecto Pedra, Papel, Tesoiras da materia Modelos de Intelixencia Artificial.  

O obxectivo principal desta tarefa √© crear un axente que trate de obter a mellor porcentaxe de vitorias posibles no Pedra, Papel, Tesoiras. Para iso, optei por implementar un axente reactivo baseado en modelos, que se serve dun historial personalizado das xogadas de cada adversario para detectar patr√≥ns no seu comportamento. Ademais disto, o axente emprega conceptos de probabilidade e as regras da cadea de Markov para predicir os movementos futuros do opo√±ente, optimizando as√≠ as s√∫as decisi√≥ns e maximizando as probabilidades de vitoria en cada partida.

## 1. Especificaci√≥n da contorna de tarefas  

| **Contorna de tarefas** | **Observable** | **Axentes** | **Determinista** | **Epis√≥dico** | **Est√°tico** | **Discreto** | **Co√±ecido** |  
|:-----------------------:|:--------------:|:-----------:|:----------------:|:-------------:|:------------:|:------------:|:------------:|  
| RPS                    | Parcial        | Multiaxente | Estoc√°stico      | Epis√≥dico      | Est√°tico      | Discreto      | Co√±ecido     |  

**RPS** ‚Æû Contorno simple, baseado na interacci√≥n por turnos entre o modelo e o oponente.

**Parcial** ‚Æû O axente non ten acceso √° seguinte acci√≥n do oponente nin √° l√≥xica que rexe as s√∫as acci√≥ns, pero si pode observar o historial de turnos xogados ata o momento.

**Multiaxente** ‚Æû Interve√±en na tarefa tanto o modelo como o seu oponente.

**Estoc√°stico** ‚Æû O resultado dunha acci√≥n non √© completamente predecible, xa que depende tanto das decisi√≥ns do oponente como de posibles compo√±entes de aleatoriedade no contorno.

**Epis√≥dico** ‚Æû Cada partida √© independente do resto; o resultado dunha partida non afecta √° seguinte, a√≠nda que o modelo pode valerse dos resultados anteriores para trazar a s√∫a estratexia.

**Est√°tico** ‚Æû O escenario da tarefa non se modifica durante a partida, esta desenv√≥lvese sen cambios din√°micos no entorno.

**Discreto** ‚Æû A variedade de acci√≥ns/estados e finita (Pedra, Papel ou Tesoiras).

**Co√±ecido** ‚Æû As regras do xogo son co√±ecidas polos participantes e non se modifican en ning√∫n momento da partida.

## 2. Identificaci√≥n do tipo de axente e estrutura 

**Axente reactivo baseado en modelos**: Un axente reactivo baseado en modelos √© un xogador que, en lugar de simplemente reaccionar en base a instrucci√≥ns preestablecidas, e capaz de lembrar o que sucedeu en partidas anteriores e utilizar esa informaci√≥n para mellorar as s√∫as decisi√≥ns futuras. Este tipo de axente non precisa facer c√°lculos moi complexos nin planificar a longo prazo; o que lle permite responder de maneira inmediata aos movementos do adversario, pero facendo uso da experiencia. A s√∫a principal vantaxe √© que, ao almacenar e analizar os movementos anteriores, pode detectar patr√≥ns no xogo do opo√±ente e adaptarse a eles, aumentando as s√∫as posibilidades de ga√±ar nas seguintes partidas.

En resumo, este axente aprende dos erros e acertos previos e utiliza esa memoria para tomar decisi√≥ns m√°is intelixentes e efectivas no xogo. Por iso, consid√©roo o tipo de axente m√°is adecuado para este caso.

![](./img/estrutura_do_axente.png)

üî¥ **Axente** ‚Æû √â o xogador automatizado que toma decisi√≥ns base√°ndose na informaci√≥n acumulada das partidas anteriores e nos patr√≥ns detectados no comportamento do opo√±ente. O axente act√∫a de maneira racional, buscando maximizar as s√∫as posibilidades de √©xito en cada partida.

üü¢ **Sensores** ‚Æû Captan informaci√≥n do entorno, como o √∫ltimo movemento do opo√±ente e o resultado da √∫ltima partida, actualizando as√≠ os datos dispo√±ibles para o axente.

üü† **Como √© o mundo agora** ‚Æû Xera unha representaci√≥n actualizada do xogo, combinando a informaci√≥n do √∫ltimo movemento do opo√±ente, os resultados recentes e os patr√≥ns detectados no historial.

üü£ **Estado** ‚Æû Almacena o historial das partidas anteriores, gardando os movementos do opo√±ente e os resultados das partidas. Esta informaci√≥n permite identificar posibles patr√≥ns de xogo do adversario.

üü£ **Como evoluciona o mundo** ‚Æû Analiza as tendencias nos movementos do opo√±ente ao longo das partidas, base√°ndose nos datos almacenados no estado, para detectar cambios na estratexia do adversario.

üü£ **Que efectos causan as mi√±as acci√≥ns**  ‚Æû Aval√≠a os resultados das acci√≥ns do axente (como a elecci√≥n de pedra, papel ou tesoira) en funci√≥n das reacci√≥ns do opo√±ente, determinando se as estratexias empregadas foron efectivas ou non.

üü† **Que acci√≥n debo tomar** ‚Æû Decide cal √© a mellor opci√≥n a xogar (pedra, papel ou tesoira) en funci√≥n dos patr√≥ns detectados, o estado actual do xogo e as regras definidas.

üü£ **Regras de condici√≥n‚Äìacci√≥n** ‚Æû Conxunto de regras que gu√≠an as decisi√≥ns do axente. Por exemplo, se detecta que o opo√±ente tende a repetir os seus √∫ltimos movementos, pode contrarrestalos base√°ndose no patr√≥n identificado.

üü¢ **Actuadores** ‚Æû Executan a decisi√≥n tomada polo axente, seleccionando pedra, papel ou tesoira para xogar a seguinte partida.

üî¥ **Medio ambiente** ‚Æû Incl√∫e o opo√±ente e as regras do xogo, proporcionando ao axente o contexto no que se desenvolven as partidas.

## 3. Ampliaci√≥n: RPSLS

Versi√≥n ampliada RPSLS (Pedra, Papel, Tesoiras, Lagarto, Spock) implementada no xogo. Neste modo introd√∫cense d√∫as novas acci√≥ns: Lagarto e Spock, coas seguintes regras adicionais:

**Pedra** ‚Æû Ga√±a contra Tesoiras e Lagarto pero perde contra Papel e Spock.

**Papel** ‚Æû Ga√±a contra Pedra e Spock pero perde contra Tesoiras e Lagarto.

**Tesoiras** ‚Æû Ga√±a contra Papel e Lagarto pero perde contra Pedra e Spock.

**Lagarto** ‚Æû Ga√±a contra Spock e Papel pero perde contra Tesoiras e Pedra.

**Spock** ‚Æû Ga√±a contra Tesoiras e Pedra pero perde contra Papel e Lagarto.

Para xogar no modo RPSLS, debes seleccionalo ao comezo do programa mediante a terminal, cando apareza a seguinte mensaxe:
``` bash
Escolle o modo de xogo: RPS[0], RPSLS[1], Axuda[8], Sa√≠r[9]: 1
```

## 4. Conclusi√≥ns

### 4.1 RPS

No modo RPS, tras probar distintas estratexias, deime conta de que √© un xogo moi simple e f√°cil de predicir. Ao poder visualizar o historial de partidas na terminal, o usuario ser√≠a sempre capaz de determinar a l√≥xica de movementos que segue o axente e adaptarse a ela. Isto evid√©nciase na imaxe, onde o meu irm√°n, tras comezar perdendo contra o axente, foi capaz de intu√≠r os seus movementos e vencelo despois de tan s√≥ catro roldas:

![](./img/Rendemento_con_historial.png)

Con esta observaci√≥n d√≠nme conta de que, co historial visible, a mellor opci√≥n para o axente ser√≠a actuar de maneira aleatoria ou utilizando patr√≥ns m√≠nimos indetectables, polo que decid√≠n que o mellor ser√≠a borrar a terminal despois de cada partida.

Sen o historial de partidas, optei por un m√©todo que combina tres estratexias diferentes cun compo√±ente de aleatoriedade entre elas: 
- Un 45% das veces o axente intenta predir o seguinte movemento base√°ndose nunha matriz de Markov simple.
- Outro 45% act√∫a segundo a porcentaxe de uso de cada movemento do usuario.
- O 10% restante elixe un movemento de forma completamente aleatoria.

Ademais, engad√≠n un comprobante para que, se se detecta alg√∫n patr√≥n simple no √∫ltimos tres movementos do usuario, o axente act√∫e en consecuencia. Isto implementouse co fin de que o axente fose o m√°is impredicible posible.

En conclusi√≥n, para que o meu axente lograse boas porcentaxes de vitoria sen ser facilmente explotable, tiven que achegar o seu razoamento √° aleatoriedade. Dado que sendo tan sinxelo o xogo, resulta moi f√°cil detectar patr√≥ns. As√≠ como o axente est√° programado para detectar e explotar patr√≥ns, o usuario tam√©n pode contraatacar explotando os do axente. Por tanto, considero que o m√°is efectivo √© dotar ao axente dunha pseudoaleatoriedade que lle permita predicir os movementos do usuario sen ser vulnerable a ser explotado.

### 4.1 RPSLS

O modo RPSLS engade m√°is variantes ao xogo, o que o fai moito m√°is dif√≠cil de predicir en comparaci√≥n co modo RPS est√°ndar. A inclusi√≥n de dous movementos adicionais, Lagarto e Spock, incrementa a complexidade do xogo e reduce a posibilidade de detectar patr√≥ns simples nas decisi√≥ns do opo√±ente.

Este aumento da complexidade fai que te√±a m√°is sentido dotar ao axente dunha intelixencia m√°is avanzada. Neste modo, o uso de estratexias como a predici√≥n baseada en matrices de Markov e a an√°lise probabil√≠stico dos movementos do adversario v√≥lvese m√°is relevante. A maior variedade de combinaci√≥ns posibles permite que o axente poida adaptarse mellor e optimizar as s√∫as decisi√≥ns, maximizando as√≠ as s√∫as probabilidades de vitoria.

En resumo, no RPSLS si que lle outorgo un maior valor a que o axente pos√∫a unha intelixencia capaz de non s√≥ reaccionar a patr√≥ns m√°is complexos, sen√≥n tam√©n de anticiparse a movementos menos obvios, facendo que sexa m√°is impredicible e efectivo neste modo m√°is amplio.

## 5. Instalaci√≥n e uso

**1.** Creamos un cartafol para o repositorio e ubic√°monos nel:
``` bash
mkdir cartafol_ppt
cd /ruta/ao/cartafol_ppt
```
**2.** Copiamos o enlace do repo e o clonamos no noso cartafol:
``` bash
git clone https://github.com/MarioUbeira/PPT-MarioUg.git
```
**3.** Creamos unha contorna virtual e a activamos:
> Linux e MacOS
``` bash
python3 -m venv nome_contorna
source nome_contorna/bin/activate
# Se aparece o nome da contorna no inicio do prompt significa que se activou correctamente:
# (nome_contorna) C:/ruta/ao/cartafol_ppt$
```
> Windows
``` powershell
python3 -m venv nome_contorna
.\nome_contorna\Scripts\activate
```
*NOTA: A activaci√≥n da contorna virtual pode fallar en Windows se as pol√≠ticas de execuci√≥n est√°n restrinxidas, nese caso utilizar o seguinte comando:*
``` powershell
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```
**4.** Descargamos e instalamos as dependencias:
``` bash
pip install -r requirements.txt
```
**5.** Execuci√≥n do programa:
> Linux e MacOS
``` bash
python3 src/main.py
```
> Windows
``` powershell
python3 .\src\main.py
```